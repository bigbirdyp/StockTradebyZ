#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ ¹æ® bj_market.csv ä¸­çš„æ–°æ—§ä»£ç æ˜ å°„å…³ç³»ï¼Œæ›´æ–°æ–‡ä»¶å¤¹ä¸­çš„ CSV æ–‡ä»¶å

åŠŸèƒ½:
- å¦‚æœæ–‡ä»¶æœ‰æ•°æ®ï¼ˆéç©ºï¼‰ï¼Œå°†æ—§ä»£ç æ–‡ä»¶åé‡å‘½åä¸ºæ–°ä»£ç 
- å¦‚æœæ–‡ä»¶æ²¡æœ‰æ•°æ®ï¼ˆç©ºæ–‡ä»¶æˆ–åªæœ‰è¡¨å¤´ï¼‰ï¼Œç›´æ¥åˆ é™¤

ç”¨æ³•:
    python update_csv_files.py --data-dir ./data/ --mapping bj_market.csv
    python update_csv_files.py --data-dir ./data/ --mapping bj_market.csv --dry-run  # é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œ
"""

import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple

import pandas as pd


def load_code_mapping(mapping_file: Path) -> Dict[str, str]:
    """
    åŠ è½½æ–°æ—§ä»£ç æ˜ å°„è¡¨
    
    Args:
        mapping_file: æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å« old å’Œ new åˆ—ï¼‰
        
    Returns:
        æ—§ä»£ç åˆ°æ–°ä»£ç çš„å­—å…¸æ˜ å°„
    """
    if not mapping_file.exists():
        print(f"é”™è¯¯: æ˜ å°„æ–‡ä»¶ {mapping_file} ä¸å­˜åœ¨", file=sys.stderr)
        sys.exit(1)
    
    try:
        df = pd.read_csv(mapping_file)
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        if "old" not in df.columns or "new" not in df.columns:
            print(f"é”™è¯¯: æ˜ å°„æ–‡ä»¶å¿…é¡»åŒ…å« 'old' å’Œ 'new' åˆ—", file=sys.stderr)
            sys.exit(1)
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        df["old"] = df["old"].astype(str)
        df["new"] = df["new"].astype(str)
        
        # åˆ›å»ºæ˜ å°„å­—å…¸
        mapping = dict(zip(df["old"], df["new"]))
        
        print(f"å·²åŠ è½½ {len(mapping)} ä¸ªä»£ç æ˜ å°„å…³ç³»\n")
        return mapping
        
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)


def check_file_has_data(csv_file: Path) -> bool:
    """
    æ£€æŸ¥ CSV æ–‡ä»¶æ˜¯å¦æœ‰æ•°æ®ï¼ˆéç©ºï¼‰
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        
    Returns:
        True è¡¨ç¤ºæœ‰æ•°æ®ï¼ŒFalse è¡¨ç¤ºæ— æ•°æ®æˆ–åªæœ‰è¡¨å¤´
    """
    try:
        # å°è¯•è¯»å–æ–‡ä»¶
        df = pd.read_csv(csv_file)
        
        # å¦‚æœ DataFrame ä¸ºç©ºæˆ–åªæœ‰åˆ—åï¼Œè®¤ä¸ºæ²¡æœ‰æ•°æ®
        if len(df) == 0:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ—éƒ½æ˜¯ç©ºå€¼
        if df.isna().all().all():
            return False
        
        return True
        
    except Exception as e:
        # å¦‚æœè¯»å–å¤±è´¥ï¼Œè®¤ä¸ºæ–‡ä»¶æœ‰é—®é¢˜ï¼Œè¿”å› Falseï¼ˆå°†ä¼šè¢«åˆ é™¤ï¼‰
        print(f"  è­¦å‘Š: è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file.name}: {e}")
        return False


def update_csv_files(data_dir: Path, mapping: Dict[str, str], dry_run: bool = False):
    """
    æ›´æ–°æ–‡ä»¶å¤¹ä¸­çš„ CSV æ–‡ä»¶å
    
    Args:
        data_dir: æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„
        mapping: æ—§ä»£ç åˆ°æ–°ä»£ç çš„æ˜ å°„å­—å…¸
        dry_run: æ˜¯å¦ä¸ºé¢„è§ˆæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œæ“ä½œï¼‰
    """
    if not data_dir.exists():
        print(f"é”™è¯¯: æ–‡ä»¶å¤¹ {data_dir} ä¸å­˜åœ¨", file=sys.stderr)
        sys.exit(1)
    
    if not data_dir.is_dir():
        print(f"é”™è¯¯: {data_dir} ä¸æ˜¯æ–‡ä»¶å¤¹", file=sys.stderr)
        sys.exit(1)
    
    # è·å–æ‰€æœ‰ CSV æ–‡ä»¶
    csv_files = list(data_dir.glob("*.csv"))
    
    if not csv_files:
        print(f"è­¦å‘Š: æ–‡ä»¶å¤¹ {data_dir} ä¸­æ²¡æœ‰æ‰¾åˆ° CSV æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶\n")
    
    if dry_run:
        print("=" * 60)
        print("é¢„è§ˆæ¨¡å¼ï¼šä»¥ä¸‹æ“ä½œå°†è¢«æ‰§è¡Œ")
        print("=" * 60 + "\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    renamed_count = 0
    deleted_count = 0
    skipped_count = 0
    
    renamed_files: List[Tuple[str, str]] = []
    deleted_files: List[str] = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for csv_file in sorted(csv_files):
        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œå³è‚¡ç¥¨ä»£ç 
        file_stem = csv_file.stem
        
        # æ£€æŸ¥æ˜¯å¦åœ¨æ˜ å°„è¡¨ä¸­
        if file_stem not in mapping:
            # ä¸åœ¨æ˜ å°„è¡¨ä¸­ï¼Œè·³è¿‡
            skipped_count += 1
            if dry_run:
                print(f"â­  {csv_file.name} - ä¸åœ¨æ˜ å°„è¡¨ä¸­ï¼Œè·³è¿‡")
            continue
        
        new_code = mapping[file_stem]
        new_file = csv_file.parent / f"{new_code}.csv"
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•°æ®
        has_data = check_file_has_data(csv_file)
        
        if has_data:
            # æœ‰æ•°æ®ï¼Œé‡å‘½åæ–‡ä»¶
            if new_file.exists() and new_file != csv_file:
                print(f"âš ï¸  è­¦å‘Š: ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ {new_file.name}ï¼Œè·³è¿‡ {csv_file.name}")
                skipped_count += 1
                continue
            
            if dry_run:
                print(f"ğŸ“ {csv_file.name} -> {new_file.name} (æœ‰æ•°æ®ï¼Œå°†é‡å‘½å)")
            else:
                try:
                    csv_file.rename(new_file)
                    print(f"âœ“ {csv_file.name} -> {new_file.name}")
                except Exception as e:
                    print(f"âœ— é‡å‘½åå¤±è´¥ {csv_file.name}: {e}")
                    skipped_count += 1
                    continue
            
            renamed_count += 1
            renamed_files.append((csv_file.name, new_file.name))
            
        else:
            # æ²¡æœ‰æ•°æ®ï¼Œåˆ é™¤æ–‡ä»¶
            if dry_run:
                print(f"ğŸ—‘  {csv_file.name} (æ— æ•°æ®ï¼Œå°†åˆ é™¤)")
            else:
                try:
                    csv_file.unlink()
                    print(f"âœ“ å·²åˆ é™¤ {csv_file.name} (æ— æ•°æ®)")
                except Exception as e:
                    print(f"âœ— åˆ é™¤å¤±è´¥ {csv_file.name}: {e}")
                    skipped_count += 1
                    continue
            
            deleted_count += 1
            deleted_files.append(csv_file.name)
    
    # æ‰“å°æ±‡æ€»ä¿¡æ¯
    print("\n" + "=" * 60)
    if dry_run:
        print("é¢„è§ˆç»“æœ:")
    else:
        print("å¤„ç†å®Œæˆ!")
    print("=" * 60)
    print(f"æ€»æ–‡ä»¶æ•°: {len(csv_files)}")
    print(f"é‡å‘½å: {renamed_count}")
    print(f"åˆ é™¤: {deleted_count}")
    print(f"è·³è¿‡: {skipped_count}")
    print("=" * 60)
    
    if renamed_files and (dry_run or len(renamed_files) <= 20):
        print("\né‡å‘½åæ–‡ä»¶åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰:")
        for old_name, new_name in renamed_files[:20]:
            print(f"  {old_name} -> {new_name}")
        if len(renamed_files) > 20:
            print(f"  ... è¿˜æœ‰ {len(renamed_files) - 20} ä¸ªæ–‡ä»¶å·²é‡å‘½å")
    
    if deleted_files and (dry_run or len(deleted_files) <= 20):
        print("\nåˆ é™¤æ–‡ä»¶åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰:")
        for file_name in deleted_files[:20]:
            print(f"  {file_name}")
        if len(deleted_files) > 20:
            print(f"  ... è¿˜æœ‰ {len(deleted_files) - 20} ä¸ªæ–‡ä»¶å·²åˆ é™¤")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="æ ¹æ®æ˜ å°„æ–‡ä»¶æ›´æ–°æ–‡ä»¶å¤¹ä¸­çš„ CSV æ–‡ä»¶å",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # é¢„è§ˆæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œæ“ä½œï¼‰
  python update_csv_files.py --data-dir ./data/ --mapping bj_market.csv --dry-run
  
  # å®é™…æ‰§è¡Œ
  python update_csv_files.py --data-dir ./data/ --mapping bj_market.csv
        """
    )
    parser.add_argument(
        "--data-dir",
        type=str,
        required=True,
        help="åŒ…å« CSV æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„"
    )
    parser.add_argument(
        "--mapping",
        type=str,
        required=True,
        help="ä»£ç æ˜ å°„æ–‡ä»¶è·¯å¾„ï¼ˆbj_market.csvï¼‰"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="é¢„è§ˆæ¨¡å¼ï¼šæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä½†ä¸å®é™…æ‰§è¡Œ"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½æ˜ å°„å…³ç³»
    mapping = load_code_mapping(Path(args.mapping))
    
    # æ›´æ–°æ–‡ä»¶
    update_csv_files(Path(args.data_dir), mapping, dry_run=args.dry_run)


if __name__ == "__main__":
    main()

